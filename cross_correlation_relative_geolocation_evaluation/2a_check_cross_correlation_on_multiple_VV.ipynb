{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b3bc47-15bf-43af-877f-108c1bcc914d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cross Correlation Check On Whole Stack with VV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f63b7e-926f-49ba-9eb5-24b997fe384e",
   "metadata": {},
   "source": [
    "### Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a1558-fe52-4b17-b0d7-101afa8fcda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import math\n",
    "import traceback\n",
    "\n",
    "from osgeo import gdal\n",
    "import shapely\n",
    "from shapely import wkt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.registration import phase_cross_correlation\n",
    "import dask.distributed\n",
    "from PIL import Image\n",
    "\n",
    "import opensarlab_lib as asfn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489baf7-1485-4f23-8e85-478a538c848f",
   "metadata": {},
   "source": [
    "### Define the search area WKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2be05-3f49-4e8e-857e-918215792798",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_WKT = \"POLYGON((-151.4766 62.3946,-143.781 62.3946,-143.781 65.6086,-151.4766 65.6086,-151.4766 62.3946))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b643f5-2500-4d39-be8a-d322d3715c46",
   "metadata": {},
   "source": [
    "### Define some later-used methods and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dcf1fa-7b56-42e1-9002-94ad3ce1f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiff_to_df(tiff_filename: str):\n",
    "    \"\"\"\n",
    "    Convert a tiff file to a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    img = gdal.Open(tiff_filename)\n",
    "    band = img.GetRasterBand(1)\n",
    "    raster0 = band.ReadAsArray()\n",
    "    df = pd.DataFrame(raster0)\n",
    "    \n",
    "    # Cutoff pixel values to 1 and 99 percentile to reduce saturation (so we can see features)\n",
    "    df = df[(df > np.percentile(df, 1)) & (df < np.percentile(df, 99))]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def plot_tiffs(df_tiffs: list, width=3):\n",
    "    \"\"\"\n",
    "    arg: df_tiffs\n",
    "    type: list of dataframes\n",
    "    \"\"\"\n",
    "    len_tiffs = len(df_tiffs)\n",
    "    number_of_x_figs = 3\n",
    "    number_of_y_figs = math.ceil(len_tiffs / number_of_x_figs)\n",
    "    \n",
    "    print(f\"A grid of ({number_of_y_figs}, {number_of_x_figs}).\")\n",
    "    \n",
    "    fig, axs = plt.subplots(number_of_y_figs, number_of_x_figs)\n",
    "    \n",
    "    for num, df_tiff in enumerate(df_tiffs):\n",
    "        xx = num % number_of_x_figs\n",
    "        yy = int(num / number_of_x_figs)\n",
    "        \n",
    "        axs[yy, xx].imshow(df_tiff['data'])\n",
    "        #vars(df)\n",
    "        axs[yy, xx].set_title(df_tiff['name'])\n",
    "\n",
    "def save_tiff_as_png(save_path_and_name: str):\n",
    "    \"\"\"\n",
    "    Convert dataframe of tiff into png.\n",
    "    \"\"\"\n",
    "    img = Image.open(save_path_and_name).convert('RGB')\n",
    "    img.save(save_path_and_name + \".png\")\n",
    "        \n",
    "# Get working directory of notebook\n",
    "CWD = pathlib.Path().absolute()\n",
    "CWD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92ed533-d4ec-4bc0-986e-d671764a5d7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get all VV tiffs files to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf2177-2943-4f27-8264-7589b929b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_paths = []\n",
    "\n",
    "# Get all VV's\n",
    "vvs = !ls {CWD}/data/S1A_*/S1A_*_VV.tif\n",
    "\n",
    "!mkdir -p {CWD}/work/\n",
    "for filepath in vvs:\n",
    "    tiff_path = pathlib.Path(filepath)\n",
    "    !cp {filepath} {CWD}/work/{tiff_path.name}\n",
    "    tiff_paths.append(f\"{CWD}/work/{tiff_path.name}\")\n",
    "    \n",
    "tiff_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29b4ed-7be1-4289-9d09-da0b95331166",
   "metadata": {},
   "source": [
    "### Display the original tiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab963eaa-fbba-457b-ba0a-57d32545d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all tiffs\n",
    "with asfn.work_dir(f\"{CWD}/work/\"):\n",
    "    df_tiffs = [{\"name\": tiff_path.split('/')[-1], \"data\": tiff_to_df(str(tiff_path))} for tiff_path in tiff_paths]\n",
    "    plot_tiffs(df_tiffs)\n",
    "del df_tiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad4c5a-c763-4b30-b4a9-3a1db65ab8b7",
   "metadata": {},
   "source": [
    "### Subset to the AOI and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f31b3-a12d-4d4e-8d03-7c75fcb28588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset reference and secondary\n",
    "with asfn.work_dir(f\"{CWD}/work/\"):\n",
    "\n",
    "    shape = wkt.loads(SEARCH_WKT)\n",
    "    bounds = shapely.bounds(shape)\n",
    "    print(f\"Shapely bounds: {bounds}\")\n",
    "    \n",
    "    tiff_subset_paths = []\n",
    "    \n",
    "    for tiff_path in tiff_paths:\n",
    "        tiff_subset_path = tiff_path.replace(\"_VV.tif\", \"_VV_subset.tif\")\n",
    "        tiff_subset_paths.append(tiff_subset_path)\n",
    "            \n",
    "        gdal.Warp(\n",
    "            str(tiff_subset_path), \n",
    "            str(tiff_path),\n",
    "            outputBounds=(bounds[0],bounds[1],bounds[2],bounds[3]),\n",
    "            outputBoundsSRS=\"EPSG:4326\"\n",
    "        )\n",
    "    \n",
    "    print(f\"Subset paths: {tiff_subset_paths}\")\n",
    "    \n",
    "    df_subset_tiffs = []\n",
    "    for tiff_subset_path in tiff_subset_paths:\n",
    "        name = tiff_subset_path.split('/')[-1]\n",
    "        data = tiff_to_df(str(tiff_subset_path))\n",
    "        \n",
    "        save_tiff_as_png(tiff_subset_path)\n",
    "        \n",
    "        df_subset_tiffs.append({\"name\": name, \"data\": data})\n",
    "    \n",
    "    plot_tiffs(df_subset_tiffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c34eee3-cbc5-4f30-ba09-faf98120cb01",
   "metadata": {},
   "source": [
    "### Show where the NANs are in the subset tiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa31e9-5435-436f-8fe8-06b83f274fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tiff_nans = [{\"name\": tiff_subset_path.split('/')[-1], \"data\": np.isnan(tiff_to_df(str(tiff_subset_path)))} for tiff_subset_path in tiff_subset_paths]\n",
    "#plot_tiffs(df_tiff_nans)\n",
    "#del df_tiff_nans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab7d2b-eab3-4096-8760-a46c51e955cf",
   "metadata": {},
   "source": [
    "### Perform cross-correlation on the tiffs, cross correlate one-by-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716fdfc-e883-49e0-8d7e-70ffce6c877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr(df_subset):\n",
    "    import dask.distributed\n",
    "    \n",
    "    def logg(level: str, msg: str):\n",
    "        dask.distributed.get_worker().log_event(level, msg)\n",
    "\n",
    "    index_1 = df_subset[0]\n",
    "    df_subset_1 = df_subset[1].get('data', None)\n",
    "    df_name_1 = df_subset[1].get('name', None)\n",
    "\n",
    "    index_2 = df_subset[2]\n",
    "    df_subset_2 = df_subset[3].get('data', None)\n",
    "    df_name_2 = df_subset[3].get('name', None)\n",
    "\n",
    "    try:\n",
    "        logg(\"my_info\", f\"Replace Nans with zeroes for ({index_1}, {index_2})\")\n",
    "        df_subset_1 = df_subset_1.replace(np.nan,0)\n",
    "        df_subset_2 = df_subset_2.replace(np.nan,0)\n",
    "\n",
    "        logg(\"my_info\", f\"Calculate the phase cross corr for ({index_1}, {index_2})\") \n",
    "        try:\n",
    "            shift, error, phase = phase_cross_correlation(np.array(df_subset_1), np.array(df_subset_2))\n",
    "            return (index_1, index_2, df_name_1, df_name_2, shift, error, phase)\n",
    "        except Exception as e:\n",
    "            #dask.distributed.get_worker().log_event(\"corr_log_error\", f\"No error and phase available for ({x}, {y})\")\n",
    "            #shift = phase_cross_correlation(df_subset_1, df_subset_2)\n",
    "            return (index_1, index_2, df_name_1, df_name_2, '', str(traceback.format_exc()), '')\n",
    "\n",
    "    except Exception as e:\n",
    "        logg(\"my_error\", f\"{e}: {traceback.format_exc()} for ({x}, {y})\")\n",
    "        return (index_1, index_2, df_name_1, df_name_2, '', str(traceback.format_exc()), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6c90f-067d-405d-87ee-17975207ac1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get set of indices, df's, names\n",
    "df_subset = []\n",
    "for first, df_subset_tiff_1 in enumerate(df_subset_tiffs):\n",
    "    for second, df_subset_tiff_2 in enumerate(df_subset_tiffs):\n",
    "        if first in [2,3,4] and second in [5,6,7]:\n",
    "            df_subset.append( (first, df_subset_tiff_1, second, df_subset_tiff_2) )\n",
    "\n",
    "upper_ram_limit = 115\n",
    "RAM_PER_WORKER_GB = 25\n",
    "\n",
    "import logging\n",
    "\n",
    "if 'futures' in locals():\n",
    "    [f.cancel() for f in futures]\n",
    "\n",
    "client = dask.distributed.Client(\n",
    "    n_workers=int(upper_ram_limit / RAM_PER_WORKER_GB),\n",
    "    #threads_per_worker=1,\n",
    "    memory_limit=f\"{RAM_PER_WORKER_GB}GB\",\n",
    "    memory_target_fraction=0.95,\n",
    "    memory_pause_fraction=0.95,\n",
    "    #nthreads=1,\n",
    "    processes=False,\n",
    "    #silence_logs=logging.ERROR\n",
    ")\n",
    "\n",
    "#client.restart()\n",
    "\n",
    "print(client)\n",
    "futures = client.map(get_corr, df_subset)\n",
    "dask.distributed.progress(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f031583-3a74-44f2-812e-7a7937ae2877",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3c42b-cd2d-49aa-80bd-4403bba13c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.gather(futures)\n",
    "df = pd.DataFrame(results, columns =['Ind 1', 'Ind 2', 'Name 1', 'Name 2', 'Shift', 'Error', 'Phase'])\n",
    "df\n",
    "#path = f\"/home/jovyan/calval-RTC/cross_correlation_relative_geolocation_evaluation/work/{df['Name 1'][1]}\"\n",
    "#print(path)\n",
    "#print(df_subset_tiffs)\n",
    "#images = plt.imshow(path)\n",
    "#images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75daaaa-d00e-4c44-8f3a-d7863de2115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Error'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8f437-77b6-47a3-ae41-9ae4378bd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Info logs: \")\n",
    "print(client.get_events(\"my_info\"))\n",
    "\n",
    "print(\"\\nError logs: \")\n",
    "client.get_events(\"my_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1fa457-110f-4fec-addd-ecc275b01f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(futures)\n",
    "\n",
    "# TO CANCEL ALL WORKERS\n",
    "#[f.cancel() for f in futures]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opera-rtc-cross-corr [conda env:.local-opera-rtc-cross-corr]",
   "language": "python",
   "name": "conda-env-.local-opera-rtc-cross-corr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
