{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f35af97-6c91-433e-aad9-dec1be04341a",
   "metadata": {},
   "source": [
    "### Some Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88d746-0230-4f87-851f-b8b23094fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import math\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from shapely import geometry\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.distributed\n",
    "from skimage.registration import phase_cross_correlation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90382517-fa81-48de-bb8b-c054d0e2d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get working directory of notebook\n",
    "CWD = pathlib.Path().absolute()\n",
    "CWD\n",
    "\n",
    "# Set some paths to be used later\n",
    "!mkdir -p \"{CWD}/work/\"\n",
    "\n",
    "ORIGINAL_DIR = CWD / \"work/original\"\n",
    "!mkdir -p \"{CWD}/work/original\"\n",
    "\n",
    "SUPERSET_DIR = CWD / \"work/superset\"\n",
    "!mkdir -p \"{CWD}/work/superset\"\n",
    "\n",
    "FLATTEN_DIR = CWD / \"work/flatten\"\n",
    "!mkdir -p \"{CWD}/work/flatten\"\n",
    "\n",
    "TILES_DIR = CWD / \"work/tiles\"\n",
    "!mkdir -p \"{CWD}/work/tiles\"\n",
    "\n",
    "RESULTS_DIR = CWD / \"work/correlation\"\n",
    "!mkdir -p \"{CWD}/work/correlation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845e7b6-8bf0-46c7-821f-49c632e15bee",
   "metadata": {},
   "source": [
    "### 1. Select VVs\n",
    "\n",
    "Choose the parent directory of all child directories contain the stack of VVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eabccbb-61fd-4c1d-a92c-8a7e82f86bb4",
   "metadata": {},
   "source": [
    "#### Clear out work directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d7360-1304-482c-91ad-3ae74bd08d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_out = input(\"Clear out work directory? (YES, NO)\")\n",
    "\n",
    "if clear_out == 'YES':\n",
    "    !rm -rf \"{CWD}/work/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2f5d1-55a0-4885-90dd-45ee98c385ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser(f'{CWD}/data/')\n",
    "fc.show_only_dirs = True\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae67db51-5826-4434-b8e7-646c9dabfb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = pathlib.Path(fc.selected_path).absolute()\n",
    "\n",
    "# Find all VVs within\n",
    "all_vv_paths = parent_directory.glob(f\"**/*_VV.tif\")\n",
    "print(list(all_vv_paths))\n",
    "\n",
    "# Move desired products to work directory.\n",
    "for source_path in all_vv_paths:\n",
    "    print(f\"Copying {source_path} to {CWD}/work/original/{source_path.name}\")\n",
    "    !cp \"{source_path}\" \"{CWD}/work/original/{source_path.name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ddfebc-8775-41aa-82f2-d08695914fcc",
   "metadata": {},
   "source": [
    "### 2. Superset VVs\n",
    "\n",
    "Scene frames have a tendency to move over time. This means that the extant coverage for the whole scene is always different per frame. For the cross-correlation to properly work and for more accurate comparison, all the scenes need to be \"normalized\" by increasing/decreasing the size of the square extant. \n",
    "\n",
    "From extant metadata, get the full superset coordinates for all stack scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31340f6-3946-4198-8e7e-c51f3cc7927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open all the tiffs and get overall coords.\n",
    "superset = {\n",
    "    'left': math.inf,\n",
    "    'bottom': math.inf,\n",
    "    'right': -math.inf,\n",
    "    'top': -math.inf\n",
    "}\n",
    "\n",
    "# The SRS is set to the first raster. It is assumed that the SRSs are the same (or close enough) for all.\n",
    "output_srs = None\n",
    "\n",
    "vv_original_paths = pathlib.Path(f\"{CWD}/work/original\").glob(f\"*_VV.tif\")\n",
    "\n",
    "for i, original_path in enumerate(vv_original_paths):\n",
    "\n",
    "    raster = rasterio.open(original_path)    \n",
    "    raster_bounds = raster.bounds\n",
    "    print(raster_bounds)\n",
    "    \n",
    "    if i == 0:\n",
    "        output_srs = raster.crs\n",
    "    \n",
    "    superset = {\n",
    "        'left': min(superset['left'], raster_bounds.left),\n",
    "        'bottom': min(superset['bottom'], raster_bounds.bottom), \n",
    "        'right': max(superset['right'], raster_bounds.right), \n",
    "        'top': max(superset['top'], raster_bounds.top)\n",
    "    }\n",
    "\n",
    "print(f\"Superset box coords: {superset}\")\n",
    "print(f\"Output SRS: {output_srs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6229d-3de8-4d11-ab62-897b2a64c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_bounds = (\n",
    "            superset['left'], \n",
    "            superset['bottom'],\n",
    "            superset['right'],\n",
    "            superset['top'],\n",
    "        )\n",
    "\n",
    "print(f\"Output bounds (superset) set to '{output_bounds}'\")\n",
    "print(f\"Output SRS set to '{output_srs}'\")\n",
    "\n",
    "# Superset and save VVs\n",
    "vv_original_paths = pathlib.Path(f\"{CWD}/work/original\").glob(f\"*_VV.tif\")\n",
    "for original_path in vv_original_paths:\n",
    "    \n",
    "    superset_path = pathlib.Path(str(original_path).replace('original', 'superset'))\n",
    "    print(f\"Taking {original_path} and supersetting to {superset_path}\")\n",
    "    \n",
    "    gdal.Warp(\n",
    "        str(superset_path),\n",
    "        str(original_path), \n",
    "        outputBounds=output_bounds,\n",
    "        outputBoundsSRS=output_srs\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4064dd33-addc-4526-abd8-2f20b43a5882",
   "metadata": {},
   "source": [
    "### 3. Flatten and Save VVs\n",
    "\n",
    "Often the VVs have extraneous high and low values that make matching difficult. So we need to get rid of these and save the intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce713694-0dc2-4dac-ad13-8ca8a77c2147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Truncated values become NaNs\n",
    "    \"\"\"\n",
    "    df[df < np.nanpercentile(df, 1)] = np.nan\n",
    "    df[df > np.nanpercentile(df, 99)] = np.nan\n",
    "    return df\n",
    "\n",
    "# Flatten and save VVs\n",
    "superset_vv_paths = pathlib.Path(f\"{CWD}/work/superset\").glob(f\"*_VV.tif\")\n",
    "\n",
    "for superset_path in superset_vv_paths:\n",
    "    print(f\"Flattening {superset_path}\")\n",
    "    \n",
    "    # Convert raster to dataframe\n",
    "    raster = rasterio.open(superset_path)\n",
    "    raster_metadata = raster.meta\n",
    "\n",
    "    raster0 = raster.read(1)\n",
    "    df_superset = pd.DataFrame(raster0)\n",
    "    \n",
    "    # Flatten raster data\n",
    "    df_flatten = flatten(df_superset)\n",
    "    \n",
    "    flatten_path = pathlib.Path(str(superset_path).replace('superset', 'flatten'))\n",
    "    \n",
    "    with rasterio.open(flatten_path, 'w', **raster_metadata) as out:\n",
    "        out.write(df_flatten, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf64fa-e58e-4b07-bdfb-fcca460567ee",
   "metadata": {},
   "source": [
    "### 4. Tile and Save VVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394ba90-1ffc-47d2-94cd-62db426fb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_NUM = 8\n",
    "Y_NUM = 8\n",
    "\n",
    "# https://gis.stackexchange.com/a/306862\n",
    "# Takes a Rasterio dataset and splits it into squares of dimensions squareDim * squareDim\n",
    "def splitImageIntoCells(input_number: int, input_file: str, output_dir: str, x_num=1, y_num=1):\n",
    "    \"\"\"\n",
    "    input_number: A sequential number representing the ordering of the scenes. This is to make later scene pairing easier.\n",
    "    input_file: Full file path of scene to be tiled.\n",
    "    output_dir: Full path of directory to place tiles.\n",
    "    x_num: Number of tiles formed in the x direction per scene.\n",
    "    y_num: Number of tiles formed in the y direction per scene.\n",
    "    \"\"\"\n",
    "\n",
    "    raster = rasterio.open(input_file)\n",
    "    \n",
    "    x_dim = raster.shape[1] // x_num\n",
    "    y_dim = raster.shape[0] // y_num\n",
    "\n",
    "    x, y = 0, 0\n",
    "    for y_iter in range(y_num):\n",
    "        y = y_iter * y_dim\n",
    "        for x_iter in range(x_num):\n",
    "            x = x_iter * x_dim\n",
    "            \n",
    "            input_filestem = pathlib.Path(input_file).stem\n",
    "            \n",
    "            output_file = f'{input_filestem}_{input_number}_{y_iter}_{x_iter}.tif'\n",
    "            print(f\"Creating tile {output_file}...\")\n",
    "            \n",
    "            # Get tile geometry\n",
    "            corner1 = raster.transform * (x, y)\n",
    "            corner2 = raster.transform * (x + x_dim, y + y_dim)\n",
    "            geom = geometry.box(corner1[0], corner1[1], corner2[0], corner2[1])\n",
    "            \n",
    "            # Get cell \n",
    "            crop, cropTransform = mask(raster, [geom], crop=True)\n",
    "            raster.meta.update(\n",
    "                {\n",
    "                    \"driver\": \"GTiff\",\n",
    "                    \"height\": crop.shape[1],\n",
    "                    \"width\": crop.shape[2],\n",
    "                    \"transform\": cropTransform,\n",
    "                    \"crs\": raster.crs\n",
    "                }\n",
    "            )\n",
    "                        \n",
    "            output_filepath = f\"{output_dir}/{output_file}\"\n",
    "            with rasterio.open(output_filepath, \"w\", **raster.meta) as out:\n",
    "                out.write(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d37caf-ceff-4e5f-be61-6bccde3dbed4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "flatten_vv_paths = pathlib.Path(f\"{CWD}/work/flatten\").glob(f\"*_VV.tif\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i, flatten_path in enumerate(flatten_vv_paths):\n",
    "    print(f\"Tileing {flatten_path}\")\n",
    "    splitImageIntoCells(i, flatten_path, f\"{CWD}/work/tiles\", x_num=X_NUM, y_num=Y_NUM)\n",
    "    \n",
    "end_time = datetime.now()\n",
    "print(f\"\\nEnd time is {end_time}\")\n",
    "print(f\"Time elapsed is {end_time - start_time}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c8f60-94de-462d-862c-7995dc61ee46",
   "metadata": {},
   "source": [
    "### 5. Correlate Tiles and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059191f0-38d8-4a86-9a8f-52c8be9a433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dask() -> dask.distributed.Client:\n",
    "    \n",
    "    RAM_PER_WORKER_GB = 20\n",
    "    NUM_WORKERS = 10\n",
    "    NUM_THREADS_PER_WORKER = 2\n",
    "\n",
    "    cluster = dask.distributed.LocalCluster(\n",
    "        threads_per_worker=NUM_THREADS_PER_WORKER,\n",
    "        n_workers=NUM_WORKERS,\n",
    "        memory_limit=f\"{RAM_PER_WORKER_GB}GB\",\n",
    "        processes=True\n",
    "    )\n",
    "\n",
    "    return dask.distributed.Client(cluster)\n",
    "\n",
    "def teardown_dask(client: dask.distributed.Client) -> None:\n",
    "    client.shutdown()\n",
    "\n",
    "def do_dask(client: dask.distributed.Client, callback, args: list):\n",
    "    try:\n",
    "        futures = client.map(callback, args)\n",
    "        dask.distributed.progress(futures)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in dask: {e}\")\n",
    "        teardown_dask(client)\n",
    "        return \n",
    "    \n",
    "    return client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d31e35a-3b89-4f21-bc5a-db3708234901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_args() -> list:\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'reference_index': '',\n",
    "            'secondary_index': '',\n",
    "            'tile_number_x': '',\n",
    "            'tile_number_y': '',\n",
    "            'ref_file_path': '',\n",
    "            'sec_file_path': ''\n",
    "        },\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    tiles_paths = pathlib.Path(f\"{CWD}/work/tiles\").glob(f\"*.tif\")\n",
    "    tiles = []\n",
    "\n",
    "    # Get index and tile numbers from path\n",
    "    for tiles_path in tiles_paths:\n",
    "\n",
    "        m = re.match(r\".*_([0-9]+)_([0-9]+)_([0-9]+).tif\", tiles_path.name)\n",
    "\n",
    "        tiles.append({\n",
    "            'index': m.group(1),\n",
    "            'tile_number_x': m.group(2),\n",
    "            'tile_number_y': m.group(3),\n",
    "            'file_path': tiles_path\n",
    "        })\n",
    "\n",
    "    tiles_df = pd.DataFrame(tiles).sort_values(by=['tile_number_x', 'tile_number_y', 'index'])\n",
    "\n",
    "    paris = []\n",
    "    for i in range(len(tiles_df.index) - 1):\n",
    "\n",
    "        ref_row = tiles_df.iloc[i]\n",
    "        sec_row = tiles_df.iloc[i+1]\n",
    "\n",
    "        # If the next row in the sorted dataframe has different tile numbers, then we are at a new set\n",
    "        if ref_row['tile_number_x'] != sec_row['tile_number_x'] or ref_row['tile_number_y'] != sec_row['tile_number_y']:\n",
    "            continue\n",
    "\n",
    "        paris.append({\n",
    "            'reference_index': ref_row['index'],\n",
    "            'secondary_index': sec_row['index'],\n",
    "            'tile_number_x': ref_row['tile_number_x'],\n",
    "            'tile_number_y': ref_row['tile_number_y'],\n",
    "            'ref_file_path': ref_row['file_path'],\n",
    "            'sec_file_path': sec_row['file_path']\n",
    "        })\n",
    "\n",
    "    return paris\n",
    "\n",
    "def correlation_callback(args: dict) -> dict:\n",
    "    \"\"\"\n",
    "    args = {\n",
    "        'reference_index': '',\n",
    "        'secondary_index': '',\n",
    "        'tile_number_x': '',\n",
    "        'tile_number_y': '',\n",
    "        'ref_file_path': '',\n",
    "        'sec_file_path': ''\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        reference_index = args['reference_index']\n",
    "        secondary_index = args['secondary_index']\n",
    "        tile_number_x = args['tile_number_x']\n",
    "        tile_number_y = args['tile_number_y']\n",
    "        ref_file_path = args['ref_file_path']\n",
    "        sec_file_path = args['sec_file_path']\n",
    "\n",
    "        ###### Reference \n",
    "        stime = datetime.now()\n",
    "        print(f\"\\nIndex {reference_index} {secondary_index}, Tile {tile_number_x} {tile_number_y}: Rendering {ref_file_path}...\")\n",
    "        rast = rasterio.open(ref_file_path)\n",
    "        raster0 = rast.read(1)\n",
    "        df_ref = pd.DataFrame(raster0)\n",
    "        print(f\"Index {reference_index} {secondary_index}, Tile {tile_number_x} {tile_number_y}: Time to complete ref: {datetime.now() - stime}\")\n",
    "\n",
    "\n",
    "        ###### Secondary\n",
    "        stime = datetime.now()\n",
    "        print(f\"\\nIndex {reference_index} {secondary_index}, Tile {tile_number_x} {tile_number_y}: Rendering {sec_file_path}...\")\n",
    "        rast = rasterio.open(sec_file_path)\n",
    "        raster0 = rast.read(1)\n",
    "        df_sec = pd.DataFrame(raster0)\n",
    "        print(f\"Index {reference_index} {secondary_index}, Tile {tile_number_x} {tile_number_y}: Time to complete sec: {datetime.now() - stime}\")\n",
    "\n",
    "\n",
    "        ###### If crop tile is more than 10% NANs, skip correlation and set return values to NaN \n",
    "        def get_percent_nans(df):\n",
    "            number_of_elements = df.size\n",
    "            number_of_nans = df.isnull().sum().sum()\n",
    "\n",
    "            return number_of_nans / number_of_elements\n",
    "\n",
    "        percent_nans_ref = get_percent_nans(df_ref)\n",
    "        percent_nans_sec = get_percent_nans(df_sec)\n",
    "\n",
    "        if percent_nans_ref > 0.10 or percent_nans_sec > 0.10:\n",
    "            print(f\"\\nIndex {reference_index} {secondary_index}, Tile {tile_number_x} {tile_number_y}: Too many NaNs. Skipping correlation....\")\n",
    "\n",
    "            result = {\n",
    "                \"reference_index\": int(reference_index),\n",
    "                \"secondary_index\": int(secondary_index),\n",
    "                \"tile_number_x\": int(tile_number_x),\n",
    "                \"tile_number_y\": int(tile_number_y),\n",
    "                \"ref_file\": str(ref_file_path),\n",
    "                \"sec_file\": str(sec_file_path),\n",
    "                \"shift_x\": np.nan,\n",
    "                \"shift_y\": np.nan, \n",
    "                \"error\": np.nan, \n",
    "                \"phase\": np.nan,\n",
    "                \"message\": \"Too many NaNs\"\n",
    "            }\n",
    "\n",
    "        ####### Cross corr without masking\n",
    "        stime = datetime.now()\n",
    "        print(f\"\\nIndex {reference_index} {secondary_index}, Tile {tile_number_x} {tile_number_y}: Finding phase correlation with nans set to zero....\")\n",
    "        shift, error, phase = phase_cross_correlation(\n",
    "\n",
    "            df_ref.replace(np.nan, 0), \n",
    "            df_sec.replace(np.nan, 0),\n",
    "\n",
    "            normalization=None\n",
    "        )\n",
    "        print(f\"Index {reference_index} {secondary_index}, Tile {tile_number_x} {tile_number_y}: Shift vector (in pixels) required to register moving_image with reference_image: {shift}\")\n",
    "        print(f\"Index {reference_index} {secondary_index}, Tile {tile_number_x} {tile_number_y}: Translation invariant normalized RMS error between reference_image and moving_image: {error}\")\n",
    "        print(f\"Index {reference_index} {secondary_index}, Tile {tile_number_x} {tile_number_y}: Global phase difference between the two images (should be zero if images are non-negative).: {phase}\\n\")\n",
    "\n",
    "        if len(list(shift)) != 2:\n",
    "            result = {\n",
    "                \"reference_index\": int(reference_index),\n",
    "                \"secondary_index\": int(secondary_index),\n",
    "                \"tile_number_x\": int(tile_number_x),\n",
    "                \"tile_number_y\": int(tile_number_y),\n",
    "                \"ref_file\": str(ref_file_path),\n",
    "                \"sec_file\": str(sec_file_path),\n",
    "                \"shift_x\": int(shift[0]),\n",
    "                \"shift_y\": int(shift[1]),\n",
    "                \"error\": np.nan, \n",
    "                \"phase\": np.nan,\n",
    "                \"message\": \"Shift is not a two element array\"\n",
    "            }\n",
    "        \n",
    "        print(f\"Index {reference_index} {secondary_index}, Tile {tile_number_x} {tile_number_y}:  Time to complete correlation: {datetime.now() - stime}\")\n",
    "\n",
    "\n",
    "        ####### Write metadata to correlation result files\n",
    "\n",
    "        result = {\n",
    "            \"reference_index\": int(reference_index),\n",
    "            \"secondary_index\": int(secondary_index),\n",
    "            \"tile_number_x\": int(tile_number_x),\n",
    "            \"tile_number_y\": int(tile_number_y),\n",
    "            \"ref_file\": str(ref_file_path),\n",
    "            \"sec_file\": str(sec_file_path),\n",
    "            \"shift_x\": int(shift[0]),\n",
    "            \"shift_y\": int(shift[1]),\n",
    "            \"error\": np.float64(error), \n",
    "            \"phase\": np.float64(phase),\n",
    "            \"message\": \"Correlation successful\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        result = {\n",
    "            \"reference_index\": int(reference_index),\n",
    "            \"secondary_index\": int(secondary_index),\n",
    "            \"tile_number_x\": int(tile_number_x),\n",
    "            \"tile_number_y\": int(tile_number_y),\n",
    "            \"ref_file\": str(ref_file_path),\n",
    "            \"sec_file\": str(sec_file_path),\n",
    "            \"shift_x\": np.nan, \n",
    "            \"shift_y\": np.nan,\n",
    "            \"error\": np.nan, \n",
    "            \"phase\": np.nan,\n",
    "            \"message\": f\"Error: {e}\"\n",
    "        }\n",
    "        \n",
    "    try:\n",
    "        result_file = pathlib.Path(f\"{CWD}/work/correlation/index_{reference_index}_{secondary_index}-tile_{tile_number_x}_{tile_number_y}.json\")\n",
    "        with open(result_file, 'w') as f:\n",
    "            json.dump(result, f)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed10930-54c8-40b0-ac0a-270077af4360",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "print(f\"\\nStart time is {start_time}\")\n",
    "\n",
    "client = setup_dask()\n",
    "correlation_results = do_dask(client, correlation_callback, get_correlation_args())\n",
    "\n",
    "teardown_dask(client)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f\"\\nEnd time is {end_time}\")\n",
    "print(f\"Time elapsed is {end_time - start_time}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c76bba-9d9b-4a18-9feb-19edd74ede06",
   "metadata": {},
   "source": [
    "### 6. Do Anaylsis on Tiles\n",
    "\n",
    "Read the correlation result files from the previous section into a Pandas DataFrame.\n",
    "\n",
    "Then perform various statistical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f86ad8-b5d5-4ad5-b740-c069e14dfdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put results into 3D Pandas dataset\n",
    "correlation_paths = pathlib.Path(f\"{CWD}/work/correlation\").glob(f\"*.json\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for corr_path in correlation_paths:\n",
    "    with open(corr_path, 'r') as f:\n",
    "        results.append(json.load(f))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Do analysis:\n",
    "# 1. Slice mean and stdev - Combine all tiles per scene pair, i.e. (reference_index, secondary_index) are the same.\n",
    "paired_df = results_df.groupby(by=['reference_index'])\n",
    "\n",
    "# 2. Temporal trend mean and stdev\n",
    "temporal_df = results_df.groupby(by=['tile_number_x', 'tile_number_y'])\n",
    "\n",
    "# 3. Global mean and stdev\n",
    "global_df = results_df.groupby(by=['reference_index', 'tile_number_x', 'tile_number_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621e8b4-43af-4165-955b-68a09540639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066c160-3a6d-45ae-9afe-914458c93898",
   "metadata": {},
   "source": [
    "Display the stats for the shift, error, and phase of the cross-correlation between two scenes in the stack.\n",
    "\n",
    "The `reference_index` is the order number of the reference scene within the stack. The stack scenes are ordered from newest to oldest.\n",
    "The `secondary_index` is the order number of the secondary scene within the stack.\n",
    "\n",
    "The `mean` value is a simple mean of all tile values. Similarity for `std`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70568c6e-088b-4703-b52b-470ff6de1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(paired_df['shift_x'].describe())\n",
    "#display(paired_df['shift_y'].describe())\n",
    "#display(paired_df['error'].describe())\n",
    "\n",
    "display(paired_df)\n",
    "\n",
    "def rms(series):\n",
    "    if np.isnan(series).all():\n",
    "        return np.nan  \n",
    "    return np.sqrt(np.nansum(np.square(series)))\n",
    "\n",
    "pdf = pd.DataFrame()\n",
    "pdf['tile_mean_x'] = paired_df['shift_x'].agg(['mean'])\n",
    "pdf['tile_mean_y'] = paired_df['shift_y'].agg(['mean'])\n",
    "pdf['error'] = paired_df['error'].agg(rms)\n",
    "#pdf = tdf.reset_index()\n",
    "display(pdf)\n",
    "\n",
    "plt.errorbar(pdf['tile_mean_x'], pdf['tile_mean_y'], yerr=pdf['error'], xerr=pdf['error']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d560e9a0-370f-4467-8cbf-e5806a64d112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f43338-f522-4b9b-8d6a-b449d4e73435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(temporal_df['shift_x'].describe())\n",
    "#display(temporal_df['shift_y'].describe())\n",
    "#display(temporal_df['error'].describe())\n",
    "\n",
    "def rms(series):\n",
    "    if np.isnan(series).all():\n",
    "        return np.nan  \n",
    "    return np.sqrt(np.nansum(np.square(series)))\n",
    "\n",
    "tdf = pd.DataFrame()\n",
    "tdf['tile_mean_x'] = temporal_df['shift_x'].agg(['mean'])\n",
    "tdf['tile_mean_y'] = temporal_df['shift_y'].agg(['mean'])\n",
    "tdf['error'] = temporal_df['error'].agg(rms)\n",
    "display(tdf)\n",
    "\n",
    "plt.errorbar(tdf['tile_mean_x'], tdf['tile_mean_y'], yerr=tdf['error'], xerr=tdf['error']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934f29b6-8394-4310-9f49-72577b9b9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(global_df['shift_x'].describe())\n",
    "display(global_df['shift_y'].describe())\n",
    "display(global_df['error'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391e143-ded5-4ed6-a554-868a23ba0b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opera-rtc-cross-corr [conda env:.local-opera-rtc-cross-corr]",
   "language": "python",
   "name": "conda-env-.local-opera-rtc-cross-corr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
