{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPERA RTC Validation: Point Target Absolute Geolocation Evaluation\n",
    "\n",
    "**Alex Lewandowski & Franz J Meyer; Alaska Satellite Facility, University of Alaska Fairbanks**\n",
    "\n",
    "This notebook analyzes the absolute geolocation quality of OPERA RTC products using corner reflectors as reference. The notebook allows for analyzing corner reflector sites in California, Oklahoma, and Alaska. \n",
    "\n",
    "**Notebook Notes**\n",
    "- Adapted for OPERA RTCs from https://github.com/OPERA-Cal-Val/calval-CSLC/blob/dev/_ALE_.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. OPERA RTC Absolute Geolocation Requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<i>The Sentinel-1-based RTC product (RTC-S1) shall meet an absolute geolocation accuracy better than or equal to 6 meters given the 30 meter RTC-S1 product resolution (i.e. 20% of the product resolution), excluding the effects of DEM errors, for at least 80% of all validation products considered.</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime as dt\n",
    "import math\n",
    "from pathlib import Path\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "\n",
    "import asf_search\n",
    "import geopandas as gpd\n",
    "import lmfit\n",
    "from lmfit.lineshapes import gaussian2d, lorentzian\n",
    "from lmfit import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyproj import Proj, CRS\n",
    "import rasterio\n",
    "from shapely import geometry\n",
    "import shapely.wkt\n",
    "\n",
    "from src.ALE_utils import oversample_slc, findCR\n",
    "current = Path('..').resolve()\n",
    "sys.path.append(str(current))\n",
    "import util.geo as util\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Select OPERA RTC Products over Validation Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Select the directory holding your OPERA RTCs\")\n",
    "fc = FileChooser(Path.cwd())\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# pass for papermill\n",
    "try:\n",
    "    data_dir = Path(fc.selected_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_path = list(Path(data_dir).rglob(f\"*_30_v1.0_mosaic.tif\"))[0]\n",
    "s1_regex = \"S1[AB]_IW_SLC__.*(?=_30_v1.0)\"\n",
    "try:\n",
    "    s1_name = re.search(s1_regex, vv_path.stem).group(0)\n",
    "except AttributeError:\n",
    "    raise Exception(f\"No S1 ID found in {vv_path.stem}\")\n",
    "\n",
    "print(s1_name)\n",
    "    \n",
    "# for Papermill\n",
    "if 'savepath' not in locals():\n",
    "    savepath = Path.cwd()/f\"absolute_geolocation_{s1_name}\"\n",
    "    savepath.mkdir(exist_ok=True)\n",
    "else:\n",
    "    savepath = Path(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = s1_name.split('T')[0].split('_')[5]\n",
    "Year = dates[0:4]\n",
    "Month = dates[4:6]\n",
    "Day = dates[6:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading required file parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(vv_path) as ds:   \n",
    "    start_x = ds.transform[2]+0.5*ds.transform[0]\n",
    "    start_y = ds.transform[5]+0.5*ds.transform[4]\n",
    "    spacing_x = ds.transform[0]\n",
    "    spacing_y = ds.transform[4]\n",
    "    width = ds.profile['width']\n",
    "    height = ds.profile['height']\n",
    "    epsg_no = ds.crs.to_epsg()\n",
    "    b = ds.bounds\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing RTC Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(vv_path) as ds:\n",
    "    rtc = ds.read(1)\n",
    "\n",
    "# Visualize Opera Data\n",
    "%matplotlib widget\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "ax.set_title(vv_path.stem)\n",
    "ax.imshow(20*np.log10(np.abs(rtc)), cmap='gray',interpolation=None, origin='upper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get Corner Reflector Data and Confirm RTC Coverage\n",
    "\n",
    "Identify which corner reflector site intersects the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = [-124.409591, 32.534156, -114.131211, 42.009518]\n",
    "ak = [-179.148909, 51.21418, 179.77847, 71.365162]\n",
    "ok = [-103.002565, 33.615833, -94.430662, 37.002206]\n",
    "\n",
    "ll_ur_corner_coords = [ca, ak, ok]\n",
    "geom = [util.poly_from_minx_miny_maxx_maxy(c) for c in ll_ur_corner_coords]\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    {\n",
    "        \"dataset\": ['California', 'Alaska', 'Oklahoma'],\n",
    "        \"geometry\": geom\n",
    "    }\n",
    ")\n",
    "gdf_4326 = gdf.set_geometry(\"geometry\")\n",
    "gdf_4326 = gdf.set_crs(f\"epsg:4326\")\n",
    "gdf = gdf_4326.to_crs(epsg_no)\n",
    "\n",
    "gdf = gdf.where(gdf.intersects(util.poly_from_minx_miny_maxx_maxy(b))).dropna()\n",
    "gdf.reset_index(inplace=True, drop=True)\n",
    "cr_zone = gdf.dataset[0]\n",
    "print(f\"Corner Reflector Site: {cr_zone}\")\n",
    "\n",
    "if cr_zone == 'California':\n",
    "    project = 'rosamond_plate_location'\n",
    "elif cr_zone == 'Alaska':\n",
    "    raise Exception(\"Alaska CR data not currently available. Check https://uavsar.jpl.nasa.gov/cgi-bin/calibration-alaska.pl to see if status has changed.\")\n",
    "elif cr_zone == 'Oklahoma':\n",
    "    project = 'nisar_plate_location'\n",
    "else:\n",
    "    raise Exception(f\"{s1_name} does not intersect CA, AK, or OK corner reflector sites\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Corner Reflector information from UAVSAR server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ = re.search(\"\\d{8}T\\d{6}\", vv_path.stem).group(0)\n",
    "date_ = dt.datetime.strptime(date_, '%Y%m%dT%H%M%S').strftime('%Y-%m-%d+%H\\u0021%M')\n",
    "\n",
    "crdata = savepath/f'{cr_zone}_{date_.split(\"+\")[0]}_crdata.csv'\n",
    "if not crdata.exists():\n",
    "    res = requests.get(f'https://uavsar.jpl.nasa.gov/cgi-bin/corner-reflectors.pl?date={str(date_)}&project={project}')\n",
    "    open(crdata, 'wb').write(res.content)\n",
    "\n",
    "# Read to pandas dataframe and rename columns\n",
    "df = pd.read_csv(crdata)\n",
    "\n",
    "df.rename(columns={'   \"Corner ID\"':'ID'}, inplace=True)\n",
    "df.rename(columns={'Latitude (deg)':'lat'}, inplace=True) \n",
    "df.rename(columns={'Longitude (deg)':'lon'}, inplace=True) \n",
    "df.rename(columns={'Azimuth (deg)':'azm'}, inplace=True)\n",
    "df.rename(columns={'Height Above Ellipsoid (m)':'hgt'}, inplace=True) \n",
    "df.rename(columns={'Side Length (m)':'slen'}, inplace=True)\n",
    "df.drop(columns=df.keys()[-1], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discovering which Corner Reflectors are within RTC coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkt_border = f'POLYGON(({b.left} {b.top},{b.right} {b.top},{b.right} {b.bottom},{b.left} {b.bottom},{b.left} {b.top}))'\n",
    "poly = shapely.wkt.loads(wkt_border)\n",
    "\n",
    "#calculating the locations of CRs in SAR image\n",
    "UTMx = []\n",
    "UTMy = []\n",
    "xloc = []\n",
    "yloc = []\n",
    "xloc_float = []\n",
    "yloc_float = []\n",
    "_in = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    _Proj = Proj(CRS.from_epsg(epsg_no))\n",
    "    _x, _y = _Proj(row['lon'], row['lat'],inverse=False)     #conversion of lat/lon of CRs to UTM coordinates\n",
    "\n",
    "    \n",
    "    #location of CRs in SLC image\n",
    "    _xloc = int(round((_x-start_x)/spacing_x))    \n",
    "    _yloc = int(round((_y-start_y)/spacing_y))\n",
    "    _\n",
    "    \n",
    "    UTMx.append(_x) \n",
    "    UTMy.append(_y)\n",
    "    xloc.append(_xloc)\n",
    "    yloc.append(_yloc)\n",
    "    xloc_float.append((_x-start_x)/spacing_x)\n",
    "    yloc_float.append((_y-start_y)/spacing_y)\n",
    "    _in.append(poly.contains(geometry.Point(_x, _y)))\n",
    "    \n",
    "df['UTMx'] = UTMx\n",
    "df['UTMy'] = UTMy\n",
    "df['xloc'] = xloc\n",
    "df['yloc'] = yloc\n",
    "df['xloc_float'] = xloc_float\n",
    "df['yloc_float'] = yloc_float\n",
    "df['inPoly'] = _in\n",
    "\n",
    "#checking whether CRs are in RTC coverage. Including only CRs within RTC image\n",
    "df = df[df['inPoly']==True]\n",
    "df.drop('inPoly', axis=1, inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing** CRs on RTC Image. We color code by reflector size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "#Displaying RTC image\n",
    "buffer = 50\n",
    "minX = df['xloc'].min() - buffer\n",
    "maxX = df['xloc'].max() + buffer\n",
    "minY = df['yloc'].min() - buffer\n",
    "maxY = df['yloc'].max() + buffer\n",
    "\n",
    "scale_ = 1.0\n",
    "exp_ = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "cax = ax.imshow(scale_*(np.abs(rtc))**exp_, cmap='gray',interpolation='bilinear', vmin=0.3, vmax=1.7, origin='upper')\n",
    "ax.set_xlim(minX,maxX)\n",
    "ax.set_ylim(minY,maxY)\n",
    "ax.axis('off')\n",
    "\n",
    "for sl in pd.unique(df.slen):\n",
    "    xx = df.loc[df['slen']==sl]['xloc']\n",
    "    yy = df.loc[df['slen']==sl]['yloc']\n",
    "    ID = df.loc[df['slen']==sl]['ID']\n",
    "    \n",
    "    if sl == 2.4384:\n",
    "        color=[0.7, 0.7, 0.7]\n",
    "    elif sl == 4.8:\n",
    "        color=[0.7, 0.7, 0.7]\n",
    "    elif sl == 2.8:\n",
    "        color=[0.7, 0.7, 0.7]\n",
    "    else:\n",
    "        color=[0.7, 0.7, 0.7]\n",
    "    \n",
    "    ax.scatter(xx,yy,color=color,marker=\"o\",facecolor='none',lw=1)\n",
    "    for _ID,_xx,_yy in zip(ID,xx,yy):\n",
    "        ax.annotate(_ID, (_xx, _yy), fontsize=10,color=[0.7, 0.7, 0.7])\n",
    "\n",
    "ax.set_aspect(1)\n",
    "plt.gca().invert_yaxis()\n",
    "fig.savefig(savepath/f'{s1_name}_S1_geoRTC_CRs.png',dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Remove Corner Reflectors Facing away from the look direction of the S1 Acquisition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = asf_search.granule_search(s1_name)\n",
    "flight_direction = results[0].properties['flightDirection']\n",
    "flight_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting CRs according to orbit direction\n",
    "if flight_direction == 'DESCENDING':\n",
    "    # descending\n",
    "    df_filter = df[df['azm']>340].reset_index(drop=True)\n",
    "    #only east-looking CRs (for right-looking descending)\n",
    "else:\n",
    "    # ascending\n",
    "    df_filter = df[df['azm']<200].reset_index(drop=True)    \n",
    "    #only west-looking CRs (for right-looking ascending)\n",
    "\n",
    "df_filter = df_filter.loc[df_filter['slen']>0.8].reset_index(drop=True)   #excluding SWOT CRs (0.7 m as a side length)\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Calculate Absolute Geolocation Error in Easting and Northing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorentzian2d(x, y, amplitude=1., centerx=0., centery=0., sigmax=1., sigmay=1.,\n",
    "                 rotation=0):\n",
    "    \"\"\"Return a two dimensional lorentzian.\n",
    "\n",
    "    The maximum of the peak occurs at ``centerx`` and ``centery``\n",
    "    with widths ``sigmax`` and ``sigmay`` in the x and y directions\n",
    "    respectively. The peak can be rotated by choosing the value of ``rotation``\n",
    "    in radians.\n",
    "    \"\"\"\n",
    "    xp = (x - centerx)*np.cos(rotation) - (y - centery)*np.sin(rotation)\n",
    "    yp = (x - centerx)*np.sin(rotation) + (y - centery)*np.cos(rotation)\n",
    "    R = (xp/sigmax)**2 + (yp/sigmay)**2\n",
    "\n",
    "    return 2*amplitude*lorentzian(R)/(np.pi*sigmax*sigmay)\n",
    "\n",
    "def gaussfit(x, y, A, x0, y0, sigma_x, sigma_y, theta):\n",
    "    theta = np.radians(theta)\n",
    "    sigx2 = sigma_x**2; sigy2 = sigma_y**2\n",
    "    a = np.cos(theta)**2/(2*sigx2) + np.sin(theta)**2/(2*sigy2)\n",
    "    b = np.sin(theta)**2/(2*sigx2) + np.cos(theta)**2/(2*sigy2)\n",
    "    c = np.sin(2*theta)/(4*sigx2) - np.sin(2*theta)/(4*sigy2)\n",
    "    \n",
    "    expo = -a*(x-x0)**2 - b*(y-y0)**2 - 2*c*(x-x0)*(y-y0)\n",
    "    return A*np.exp(expo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpeak = []\n",
    "ypeak = []\n",
    "snr = []\n",
    "\n",
    "ovsFactor=32\n",
    "\n",
    "for ID, xoff, yoff in zip(df_filter['ID'],df_filter['xloc'],df_filter['yloc']):\n",
    "    # crop a patch of 10*10 with center at the calculated CR position\n",
    "    pxbuff = 5\n",
    "    pybuff = 5\n",
    "    cropcslc = rtc[(yoff-pybuff):(yoff+pybuff),(xoff-pxbuff):(xoff+pxbuff)]\n",
    "    \n",
    "    if np.isnan(np.mean(cropcslc))!=True:\n",
    "       # _snr = get_snr_peak(cropcslc)\n",
    "\n",
    "        # find the peak amplitude in the 10*10 patch\n",
    "        yind,xind = np.unravel_index(np.argmax(np.abs(cropcslc), axis=None), cropcslc.shape)\n",
    "    \n",
    "        # give a warning if the peak and the calculated postion are too far\n",
    "        dyind = yind-pybuff; dxind = xind-pxbuff\n",
    "        dist = math.sqrt(dyind**2+dxind**2)\n",
    "        if dist > 2.0:\n",
    "            warnings.warn(f'the most bright pixel and the xloc is too far for CR {ID}')\n",
    "    \n",
    "        plt.rcParams.update({'font.size': 14})\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 7))\n",
    "        ax[0].imshow(np.abs(cropcslc), cmap='gray',interpolation=None, origin='upper')\n",
    "        ax[0].plot(xind,yind,'r+')\n",
    "        ax[0].set_title(f'Corner Reflector ID: {ID}')\n",
    "    \n",
    "        # crop a patch of 32*32 but with its center at the peak\n",
    "        xbuff = 32\n",
    "        ybuff = 32\n",
    "        ycrop = np.arange(yoff+dyind-ybuff,yoff+dyind+ybuff)\n",
    "        xcrop = np.arange(xoff+dxind-xbuff,xoff+dxind+xbuff)\n",
    "        cropcslc = rtc[ycrop,:][:,xcrop]\n",
    "\n",
    "        # Oversample slc\n",
    "        cropcslc_ovs,ycrop_ovs,xcrop_ovs = oversample_slc(cropcslc,sampling=ovsFactor,y=ycrop,x=xcrop)\n",
    "\n",
    "        numpix = 2\n",
    "    \n",
    "        # find the peak amplitude again in a 2 x 2 patch, it correspond to \n",
    "        # (2*ovsFactor) x (2*ovsFactor) in oversampled slc\n",
    "        yoff2 = int(cropcslc_ovs.shape[0]/2)\n",
    "        xoff2 = int(cropcslc_ovs.shape[1]/2)\n",
    "        cropcslc2 = cropcslc_ovs[yoff2-numpix*ovsFactor:yoff2+numpix*ovsFactor,\n",
    "                               xoff2-numpix*ovsFactor:xoff2+numpix*ovsFactor]\n",
    "        yind2,xind2 = np.unravel_index(np.argmax(abs(cropcslc2), axis=None), cropcslc2.shape)\n",
    "        dyind2 = yind2-numpix*ovsFactor; dxind2 = xind2-numpix*ovsFactor\n",
    "    \n",
    "        N = numpix*2* ovsFactor\n",
    "        x = np.linspace(0,numpix*2*ovsFactor-1,N)\n",
    "        y = np.linspace(0,numpix*2*ovsFactor-1,N)\n",
    "        Xg, Yg = np.meshgrid(x, y)\n",
    "        fmodel = Model(gaussfit, independent_vars=('x','y'))\n",
    "        theta = 0.1  # deg\n",
    "        x0 = numpix* ovsFactor\n",
    "        y0 = numpix* ovsFactor\n",
    "        sigx = 2\n",
    "        sigy = 5\n",
    "        A = np.max(np.abs(cropcslc2))\n",
    "\n",
    "        result = fmodel.fit(np.abs(cropcslc2), x=Xg, y=Yg, A=A, x0=x0, y0=y0, sigma_x=sigx, sigma_y=sigy, theta=theta)\n",
    "        fit = fmodel.func(Xg, Yg, **result.best_values)\n",
    "    \n",
    "        dyind3 = result.best_values['y0']-numpix*ovsFactor; dxind3 = result.best_values['x0']-numpix*ovsFactor\n",
    "    \n",
    "        ax[1].imshow(np.abs(cropcslc2), cmap='gray',interpolation=None, origin='upper')\n",
    "        ax[1].plot(xind2,yind2,'r+')\n",
    "        ax[1].plot(result.best_values['x0'],result.best_values['y0'],'b+')\n",
    "        ax[1].set_title(f'Oversampled Corner Reflector ID: {ID}')\n",
    "    \n",
    "        ax[2].imshow(np.abs(fit), cmap='gray',interpolation=None, origin='upper')\n",
    "        ax[2].plot(xind2,yind2,'r+')\n",
    "        ax[2].plot(result.best_values['x0'],result.best_values['y0'],'b+')\n",
    "        ax[2].set_title(f'Oversampled Corner Reflector ID: {ID}')\n",
    "    \n",
    "        # crop a patch of 3x3 oversampled patch with center at the peak\n",
    "        cropcslc3 = cropcslc_ovs[yoff2+dyind2-1:yoff2+dyind2+2,xoff2+dxind2-1:xoff2+dxind2+2]\n",
    "        ycrop2 = ycrop_ovs[yoff2+dyind2-1:yoff2+dyind2+2]\n",
    "        xcrop2 = xcrop_ovs[xoff2+dxind2-1:xoff2+dxind2+2]\n",
    "        xxcrop2,yycrop2 = np.meshgrid(xcrop2,ycrop2)\n",
    "        xxcrop2_f = xxcrop2.flatten()\n",
    "        yycrop2_f = yycrop2.flatten()\n",
    "        cropcslc2_f = cropcslc3.flatten()\n",
    "\n",
    "        # Check if pixel values in a patch are non-NaN\n",
    "        valid = ~(np.isnan(cropcslc2_f))\n",
    "        count_valid = np.count_nonzero(valid)\n",
    "\n",
    "        if count_valid == 0:\n",
    "            _ypeak, _xpeak = [np.nan, np.nan]\n",
    "\n",
    "        else:\n",
    "            _ypeak,_xpeak = findCR(np.abs(cropcslc2_f[valid]),yycrop2_f[valid],xxcrop2_f[valid],\n",
    "                                x_bound=[xcrop2[0],xcrop2[-1]],y_bound=[ycrop2[0],ycrop2[-1]],method=\"para\")\n",
    "\n",
    "        #xpeak.append(_xpeak)\n",
    "        #ypeak.append(_ypeak)\n",
    "        #xpeak.append(xoff+dxind+dxind2/ovsFactor)\n",
    "        #ypeak.append(yoff+dyind+dyind2/ovsFactor)\n",
    "        xpeak.append(xoff+dxind+dxind3/ovsFactor)\n",
    "        ypeak.append(yoff+dyind+dyind3/ovsFactor)\n",
    "        #snr.append(_snr)\n",
    "    else:\n",
    "        xpeak.append(np.nan)\n",
    "        ypeak.append(np.nan)\n",
    "    \n",
    "df_filter['xloc_CR'] = xpeak\n",
    "df_filter['yloc_CR'] = ypeak\n",
    "#df_filter['snr'] = snr\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing CR Location Measurements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df_filter.dropna().reset_index(drop=True)\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Uncomment this Line to Drop CRs that were Poorly Identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filter = df_filter.drop([2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Calculating Absolute Geolocation Numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#absloute geolocation error in range and azimuth\n",
    "ALE_Rg = (df_filter['xloc_CR'] -  df_filter['xloc_float']) * spacing_x\n",
    "ALE_Az = (df_filter['yloc_CR'] - df_filter['yloc_float']) * spacing_y\n",
    "\n",
    "#test_Rg = ((df_filter['xloc_float'] % 1.0)-0.5)\n",
    "#test_Az = -((df_filter['yloc_float'] % 1.0)-0.5)\n",
    "\n",
    "test_Rg = ((df_filter['xloc']-df_filter['xloc_float']))\n",
    "test_Az = -((df_filter['yloc']-df_filter['yloc_float']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALE_Az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALE_Rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(test_Az**2 + test_Rg**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Removing Corner Reflectors that are near the Edge of the Pixel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we cannot interpolate into the pixel, corner reflectors that sit near the edge of the pixel can bias our offset estimate. Therefore, we are removing corner reflectors near pixel edges before we analyze summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpix = np.sqrt(test_Az**2 + test_Rg**2)\n",
    "keepind = []\n",
    "for idx, row in subpix.items():\n",
    "    if subpix[idx] <=0.55:\n",
    "        keepind.append(idx)\n",
    "print(keepind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Plot Absolute Geolocation Error in Easting and Northing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "requirement = plt.Rectangle((-3.0,-3.0), 6.0, 6.0, fill=False, edgecolor='grey', label='Requirement')\n",
    "ax.add_patch(requirement)\n",
    "#sc = ax.scatter(ALE_Rg, ALE_Az, s=200, c=df_filter['slen'], alpha=0.6, marker='o')\n",
    "sc = ax.scatter(ALE_Rg[keepind], ALE_Az[keepind], s=100, c='k', alpha=0.6, marker='o')\n",
    "#ax.legend(*sc.legend_elements(),facecolor='lightgray')\n",
    "#ax.get_legend().set_title('side length (m)')\n",
    "\n",
    "\n",
    "for ii, txt in enumerate(df_filter.iloc[keepind,0]):\n",
    "    ax.annotate(txt, (ALE_Rg[keepind[ii]],ALE_Az[keepind[ii]]), color='black',xytext=(0, 5), textcoords='offset points')   #putting IDs in each CR\n",
    "    \n",
    "ax.grid(True)\n",
    "ax.set_xlim(-15.25,15.25)\n",
    "ax.set_ylim(-15.25,15.25)\n",
    "ax.axhline(0, color='black')\n",
    "ax.axvline(0, color='black')\n",
    "\n",
    "#np.std(data, ddof=1) / np.sqrt(np.size(data))\n",
    "\n",
    "ax.set_title(f'Easting: {np.round(np.nanmean(ALE_Rg[keepind]), 3)} +/- {np.round(np.nanstd(ALE_Rg[keepind]) / np.sqrt(np.size(ALE_Rg[keepind])),3)} m, \\\n",
    "    Northing: {np.round(np.nanmean(ALE_Az[keepind]),3)}, +/- {np.round(np.nanstd(ALE_Az[keepind]) / np.sqrt(np.size(ALE_Az[keepind])),3)} m')\n",
    "ax.set_xlabel('Easting error (m)')\n",
    "ax.set_ylabel('Northing error (m)')\n",
    "fig.suptitle('Absolute Geolocation Error')\n",
    "\n",
    "plt.errorbar(np.round(np.nanmean(ALE_Rg[keepind]), 3), np.round(np.nanmean(ALE_Az[keepind]),3),\\\n",
    "             xerr=np.round(np.nanstd(ALE_Rg[keepind]) / np.sqrt(np.size(ALE_Rg[keepind])),3), yerr=np.round(np.nanstd(ALE_Az[keepind]) / np.sqrt(np.size(ALE_Az[keepind])),3), \\\n",
    "             barsabove=True, capsize=8, capthick=2, fmt='ro', linewidth=2, markersize=20)\n",
    "\n",
    "output = f\"{s1_name}_GeolocationPLOT.png\"\n",
    "plt.savefig(savepath/output, dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s1_name)\n",
    "print(np.round(np.nanmean(ALE_Rg[keepind]), 3))\n",
    "print(np.round(np.nanstd(ALE_Rg[keepind]) / np.sqrt(np.size(ALE_Rg[keepind])),3))\n",
    "print(np.round(np.nanmean(ALE_Az[keepind]),3))\n",
    "print(np.round(np.nanstd(ALE_Az[keepind]) / np.sqrt(np.size(ALE_Az[keepind])),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ALE\n",
    "\n",
    "#msize = (df_filter['CRZscrores'] - np.min(df_filter['CRZscrores']) + 0.000001) * 100.0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "requirement = plt.Rectangle((-3.0,-3.0), 6.0, 6.0, fill=False, edgecolor='grey', label='Requirement')\n",
    "ax.add_patch(requirement)\n",
    "#sc = ax.scatter(ALE_Rg, ALE_Az, s=200, c=df_filter['slen'], alpha=0.6, marker='o')\n",
    "sc = ax.scatter(test_Rg, test_Az, s=100, c='k', alpha=0.6, marker='o')\n",
    "\n",
    "\n",
    "for ii, txt in enumerate(df_filter.iloc[:,0]):\n",
    "    ax.annotate(txt, (test_Rg[ii],test_Az[ii]), color='black',xytext=(0, 5), textcoords='offset points')   #putting IDs in each CR\n",
    "    \n",
    "ax.grid(True)\n",
    "ax.set_xlim(-1.25,1.25)\n",
    "ax.set_ylim(-1.25,1.25)\n",
    "ax.axhline(0, color='black')\n",
    "ax.axvline(0, color='black')\n",
    "\n",
    "ax.set_title(f'Easting: {np.round(np.nanmean(test_Rg), 3)} +/- {np.round(np.nanstd(test_Rg) / np.sqrt(np.size(test_Rg)),3)} m, \\\n",
    "    Northing: {np.round(np.nanmean(test_Az),3)}, +/- {np.round(np.nanstd(test_Az) / np.sqrt(np.size(test_Az)),3)} m')\n",
    "ax.set_xlabel('Easting error (m)')\n",
    "ax.set_ylabel('Northing error (m)')\n",
    "fig.suptitle('Fractional Offset from Pixel Center')\n",
    "\n",
    "plt.errorbar(np.round(np.nanmean(test_Rg), 3), np.round(np.nanmean(test_Az),3),\\\n",
    "             xerr=np.round(np.nanstd(test_Rg) / np.sqrt(np.size(test_Rg)),3), yerr=np.round(np.nanstd(test_Az) / np.sqrt(np.size(test_Az)),3), \\\n",
    "             barsabove=True, capsize=8, capthick=2, fmt='ro', linewidth=2, markersize=20)\n",
    "\n",
    "output = f\"{s1_name}_FracOffset.png\"\n",
    "plt.savefig(savepath/output, dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Write Results into a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALE_csv = savepath.parent/f\"{cr_zone}_ALE30-Results.csv\"\n",
    "\n",
    "fields = [\"Granule\", \"Year\", \"Month\", \"Day\", \"Easting_Bias\", \"sig_Easting_Bias\", \"Northing_Bias\", \"sig_Northing_Bias\"]\n",
    "\n",
    "row = [s1_name, Year, Month, Day,  \n",
    "       np.round(np.nanmean(ALE_Rg[keepind]), 3), np.round(np.nanstd(ALE_Rg[keepind]) / np.sqrt(np.size(ALE_Rg[keepind])),3),\n",
    "       np.round(np.nanmean(ALE_Az[keepind]), 3), np.round(np.nanstd(ALE_Az[keepind]) / np.sqrt(np.size(ALE_Az[keepind])),3)]\n",
    "\n",
    "if not ALE_csv.exists():\n",
    "    with open(ALE_csv, 'w') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(fields)\n",
    "        csvwriter.writerow(row)\n",
    "else:\n",
    "    with open(ALE_csv, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        s1_names = [c[0] for c in list(csvreader)]\n",
    "    if s1_name not in s1_names:\n",
    "        with open(ALE_csv, 'a') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALE_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ALE_OPERA_RTC.ipynb - Version 2.0.0 - April 2023*\n",
    "\n",
    "*Change log*\n",
    "\n",
    "- Made CR discovery more robust\n",
    "- Added average visualization in geolocation plot\n",
    "- Made formatting changes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opera_calval_rtc [conda env:.local-opera_calval_rtc]",
   "language": "python",
   "name": "conda-env-.local-opera_calval_rtc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "11cc5ba7f1a5f01f06eec0d777911b7e71c9b1fdadce8b2ef27933e84970f723"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
